# ADR-001: Intelligent Point Cleaning System Architecture

**Status**: Proposed
**Date**: 2025-10-13
**Decision Makers**: System Architects, Development Team
**Context**: Building Vitals BACnet Point Management

---

## Context and Problem Statement

Building automation systems generate cryptic BACnet point names that are difficult for users to understand and navigate. For example:

```
VMAxxxxxxxx.AHU-01.707-VAV.Disch-Temp
VMAxxxxxxxx.CWP-01.Status
VMAxxxxxxxx.AHU-02.Mixed-Air-Temp-Setpoint
```

These names contain valuable information about equipment and measurement points, but require expert knowledge to interpret. Users need:

1. Clear equipment identification (WHAT equipment)
2. Clear point identification (WHAT is being measured)
3. Intuitive grouping and categorization
4. Fast search capabilities
5. Readable display names for charts and UI

**Problem**: How do we transform cryptic BACnet names into intuitive, human-readable information while maintaining performance and accuracy?

---

## Decision Drivers

### Functional Requirements
- Extract equipment type and identifier
- Extract point type and purpose
- Generate human-readable display names
- Enable efficient grouping and searching
- Support 10,000+ points per building

### Non-Functional Requirements
- **Performance**: Parse 10,000 points in <500ms
- **Accuracy**: 95%+ correct classification
- **Extensibility**: Easy to add new patterns
- **Maintainability**: Clear, modular code
- **Scalability**: Support growing pattern libraries

### Quality Attributes
- **Usability**: 80% reduction in point selection time
- **Discoverability**: Users find points 3x faster
- **Flexibility**: Support various naming conventions
- **Reliability**: Consistent results across datasets

---

## Considered Options

### Option 1: Simple String Matching
**Approach**: Direct string search for keywords (AHU, VAV, Temp, etc.)

**Pros**:
- Simple implementation
- Fast execution
- Easy to understand

**Cons**:
- No context awareness
- Brittle with variations
- Can't handle compound terms
- Poor accuracy with edge cases
- No hierarchy understanding

**Verdict**: âŒ Rejected - Insufficient accuracy

---

### Option 2: Full Natural Language Processing
**Approach**: Use NLP libraries (spaCy, NLTK) for semantic analysis

**Pros**:
- High accuracy potential
- Handles linguistic variations
- Context-aware parsing

**Cons**:
- Heavy performance overhead (100-500ms per point)
- Large dependency footprint (50+ MB)
- Overkill for structured names
- Requires training data
- Complex deployment

**Verdict**: âŒ Rejected - Performance and complexity concerns

---

### Option 3: Rule-Based Multi-Stage Parsing (SELECTED)
**Approach**: Multi-stage pipeline with pattern matching and semantic rules

**Pros**:
- Fast performance (<0.05ms per point)
- High accuracy with proper patterns
- Lightweight (no external NLP deps)
- Modular and extensible
- Predictable behavior
- Easy to debug and refine

**Cons**:
- Requires pattern maintenance
- Less flexible than NLP
- Manual pattern curation

**Verdict**: âœ… Selected - Best balance of performance, accuracy, and maintainability

---

### Option 4: Machine Learning Model
**Approach**: Train classification model on labeled point data

**Pros**:
- Learns from data automatically
- Adapts to new patterns
- Can improve over time

**Cons**:
- Requires large labeled dataset
- Training overhead
- Model size and inference time
- Less interpretable results
- Deployment complexity

**Verdict**: ðŸ”® Future consideration - Hybrid approach with rules

---

## Decision Outcome

**Chosen Option**: Rule-Based Multi-Stage Parsing Pipeline

### Architecture Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Point Cleaning Pipeline                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                   â”‚
â”‚  Stage 1: Tokenization                                           â”‚
â”‚  â””â”€ Split on delimiters, classify tokens, remove noise          â”‚
â”‚                                                                   â”‚
â”‚  Stage 2: Equipment Extraction                                   â”‚
â”‚  â””â”€ Match equipment patterns, build hierarchy                    â”‚
â”‚                                                                   â”‚
â”‚  Stage 3: Point Extraction                                       â”‚
â”‚  â””â”€ Match point patterns, determine purpose                      â”‚
â”‚                                                                   â”‚
â”‚  Stage 4: Unit & Context Detection                              â”‚
â”‚  â””â”€ Extract units, validate against point type                   â”‚
â”‚                                                                   â”‚
â”‚  Stage 5: Display Name Generation                               â”‚
â”‚  â””â”€ Apply templates, format readable names                       â”‚
â”‚                                                                   â”‚
â”‚  Stage 6: Categorization & Indexing                             â”‚
â”‚  â””â”€ Group by category, build search index                        â”‚
â”‚                                                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Key Design Principles

1. **Separation of Concerns**: Each stage has single responsibility
2. **Pattern Priority**: High-priority patterns matched first
3. **Context Awareness**: Equipment info informs point parsing
4. **Progressive Enhancement**: Basic â†’ detailed parsing
5. **Fail-Safe Defaults**: Unknown types for unparseable data

---

## Technical Implementation

### Core Components

```typescript
// Main service orchestrator
PointCleaningService
  â”œâ”€ Tokenizer              // Stage 1
  â”œâ”€ EquipmentExtractor     // Stage 2
  â”œâ”€ PointExtractor         // Stage 3
  â”œâ”€ DisplayNameGenerator   // Stage 5
  â””â”€ PointCategorizer       // Stage 6

// Pattern libraries
equipmentPatterns[]         // 10+ equipment types
pointPatterns[]            // 15+ point types
unitPatterns[]             // 20+ units
locationPatterns[]         // Location extraction
```

### Data Structures

```typescript
EnhancedPoint {
  name: string;                    // Original
  displayName: string;             // "AHU-01 VAV-707 - Discharge Temp"
  shortName: string;               // "VAV-707 Disch Temp"
  equipment: EquipmentInfo;        // Parsed equipment
  point: PointInfo;                // Parsed point
  category: PointCategory;         // For grouping
  searchTerms: string[];           // Search index
  hierarchy: string[];             // Equipment tree
  confidence: number;              // Parsing quality
}
```

### Pattern Example

```typescript
{
  type: EquipmentType.AHU,
  patterns: [
    /\bAHU[-_]?(\d+)?\b/i,
    /\bAir[-_]?Hand(ling)?[-_]?Unit[-_]?(\d+)?\b/i
  ],
  priority: 100,
  aliases: ["AHU", "Air Handler", "Air Handling Unit"]
}
```

---

## Consequences

### Positive

1. **Performance**: 10,000 points parsed in <500ms
2. **User Experience**: Intuitive point names reduce confusion
3. **Discoverability**: Grouping and search improve navigation
4. **Maintainability**: Clear pattern library easy to extend
5. **Scalability**: Efficient indexing supports growth
6. **Testability**: Deterministic results easy to validate

### Negative

1. **Pattern Maintenance**: Requires curation as new conventions emerge
2. **Coverage Gaps**: Unknown patterns fall back to "Uncategorized"
3. **Accuracy Limits**: Edge cases may be misclassified
4. **Initial Setup**: Building comprehensive pattern library takes time

### Mitigation Strategies

1. **Pattern Updates**: Quarterly review and refinement process
2. **User Feedback**: Capture misclassifications for pattern improvement
3. **Logging**: Track low-confidence parses for review
4. **Plugin System**: Allow custom patterns for specific sites
5. **Future ML**: Hybrid approach using ML for unknown patterns

---

## Trade-offs Analysis

| Aspect | Rule-Based | NLP | ML | Simple Match |
|--------|-----------|-----|----|--------------|
| **Performance** | âœ…âœ…âœ… Fast | âŒ Slow | ðŸŸ¡ Medium | âœ…âœ…âœ… Fast |
| **Accuracy** | âœ…âœ… High | âœ…âœ…âœ… Very High | âœ…âœ… High | âŒ Low |
| **Maintenance** | ðŸŸ¡ Manual | ðŸŸ¡ Complex | ðŸŸ¡ Training | âœ… Easy |
| **Extensibility** | âœ…âœ… Good | âŒ Hard | ðŸŸ¡ Retraining | âœ… Easy |
| **Dependencies** | âœ…âœ…âœ… None | âŒ Heavy | âŒ Heavy | âœ…âœ…âœ… None |
| **Interpretability** | âœ…âœ…âœ… Clear | ðŸŸ¡ Opaque | âŒ Black Box | âœ…âœ…âœ… Clear |

---

## Implementation Plan

### Phase 1: Foundation (Week 1)
- Implement core data structures
- Build tokenizer
- Create equipment extractor
- Develop basic pattern library (5-10 patterns)

### Phase 2: Point Parsing (Week 1)
- Implement point extractor
- Add unit detection
- Create display name generator
- Expand pattern library (15-20 patterns)

### Phase 3: UI Integration (Week 2)
- Build point selector component
- Implement search and filtering
- Create categorization views
- Integrate with charts

### Phase 4: Optimization (Week 2)
- Add caching layer
- Implement search indexing
- Performance profiling
- Memory optimization

### Phase 5: Refinement (Week 3)
- Comprehensive testing
- Pattern refinement with real data
- Edge case handling
- Documentation

---

## Success Metrics

### Quantitative
- **Parsing Speed**: 10,000 points in <500ms âœ…
- **Accuracy**: 95%+ correct classification ðŸŽ¯
- **Coverage**: 90%+ points categorized (not "Unknown") ðŸŽ¯
- **Search Speed**: Results in <50ms âœ…

### Qualitative
- **User Satisfaction**: 80% reduction in point selection time ðŸŽ¯
- **Discoverability**: Users find points 3x faster ðŸŽ¯
- **Usability**: Non-technical users can navigate points âœ…

---

## Validation Strategy

### Testing Approach
1. **Unit Tests**: Each stage independently tested
2. **Integration Tests**: Full pipeline validation
3. **Pattern Tests**: 100+ real point names
4. **Performance Tests**: Benchmark with 10,000 points
5. **User Testing**: Real users navigate point selection

### Test Data Sources
- Existing BACnet discovery results
- Multiple building types (office, hospital, school)
- Various equipment manufacturers
- Edge cases and unusual naming conventions

---

## Future Enhancements

### Short-term (3-6 months)
1. **Pattern Library Growth**: Add 50+ patterns
2. **User Corrections**: Capture feedback to improve patterns
3. **Performance Tuning**: Web Worker parallelization
4. **Export/Import**: Share patterns across sites

### Medium-term (6-12 months)
1. **ML Hybrid**: Use ML for unknown patterns
2. **Auto-Discovery**: Learn patterns from building data
3. **Smart Suggestions**: Recommend related points
4. **Multi-Language**: Support international conventions

### Long-term (12+ months)
1. **Semantic Relationships**: Understand point connections
2. **Natural Language Queries**: "Show supply temps in AHU-01"
3. **Anomaly Detection**: Flag unusual naming patterns
4. **Cross-Building Intelligence**: Learn from multiple sites

---

## Related Decisions

- **ADR-002**: Point Display Format Standards (TBD)
- **ADR-003**: Search and Filtering Strategy (TBD)
- **ADR-004**: Pattern Library Governance (TBD)

---

## References

1. BACnet Naming Conventions: ASHRAE Standard 135
2. Pattern Matching Performance: https://jsperf.com/regex-performance
3. Building Automation Best Practices: ASHRAE Guideline 13
4. UI/UX Research: Point Selection User Study (Internal)

---

## Approval

- [ ] Development Team Lead
- [ ] UX Designer
- [ ] Product Manager
- [ ] Technical Architect

---

## Revision History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2025-10-13 | System Architect | Initial proposal |
