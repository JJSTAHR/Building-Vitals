name: Supabase RAW Backfill (Paginated)

on:
  schedule:
    - cron: '0 2 * * *'  # daily at 2 AM UTC - fetches previous day's data (all sites)
  workflow_dispatch:
    inputs:
      site:
        description: "Optional: run for a single site (e.g., ses_falls_city). If empty, runs for all sites."
        required: false
      start_iso:
        description: "Start ISO (e.g., 2025-10-01T00:00:00Z). Default: end-60m"
        required: false
      end_iso:
        description: "End ISO (default: now)"
        required: false
      chunk_minutes:
        description: "Chunk size in minutes"
        required: true
        default: "10"
      page_size:
        description: "ACE paginated page size"
        required: true
        default: "100000"
      max_chunks:
        description: "Max chunks to process this run"
        required: true
        default: "12"

concurrency:
  group: supabase-raw-backfill
  cancel-in-progress: true

permissions:
  contents: read

jobs:
  discover:
    runs-on: ubuntu-latest
    outputs:
      sites: ${{ steps.sites.outputs.sites }}
    steps:
      - name: Connectivity check (Supabase REST)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -z "${SUPABASE_URL:-}" ] || [ -z "${SUPABASE_SERVICE_ROLE_KEY:-}" ]; then
            echo "Supabase secrets are missing" >&2
            exit 1
          fi
          base="${SUPABASE_URL%/}"
          # Light HEAD-equivalent via limit=1; should return 200 (apikey is sufficient)
          code=$(curl -s -o /dev/null -w "%{http_code}" \
            "${base}/rest/v1/points?select=name&limit=1" \
            -H "apikey: ${SUPABASE_SERVICE_ROLE_KEY}")
          if [ "$code" != "200" ]; then
            echo "Supabase REST check failed: HTTP $code" >&2
            exit 1
          fi
      - name: Determine site list (single or all)
        id: sites
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          INPUT_SITE: ${{ github.event.inputs.site }}
        shell: bash
        run: |
          set -euo pipefail
          if [ -n "${INPUT_SITE:-}" ]; then
            echo "sites=[\"$INPUT_SITE\"]" >> $GITHUB_OUTPUT
            exit 0
          fi
          base="${SUPABASE_URL%/}"
          resp=$(curl -sS "${base}/rest/v1/rpc/distinct_sites" \
            -H "apikey: ${SUPABASE_SERVICE_ROLE_KEY}" \
            -H "Authorization: Bearer ${SUPABASE_SERVICE_ROLE_KEY}")
          if [ -z "$resp" ]; then resp="[]"; fi
          # Ensure compact JSON array
          echo "sites=$(echo "$resp" | jq -c .)" >> $GITHUB_OUTPUT

  backfill:
    runs-on: ubuntu-latest
    needs: discover
    strategy:
      fail-fast: false
      matrix:
        site: ${{ fromJSON(needs.discover.outputs.sites) }}
    timeout-minutes: 55
    env:
      SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
      SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
      ACE_API_KEY: ${{ secrets.ACE_API_KEY }}
      PROXY_URL: https://ace-iot-timeseries-prod.jstahr.workers.dev
      USE_ACE_CLI: "0"
      ACE_API_BASE: https://flightdeck.aceiot.cloud/api
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r scripts/python/requirements.txt

      - name: Compute defaults
        id: when
        shell: bash
        run: |
          # Default deep backfill start to 2025-01-01; leave end blank to use earliest existing ts
          START_ISO="${{ github.event.inputs.start_iso }}"
          if [ -z "$START_ISO" ]; then START_ISO="2025-01-01T00:00:00Z"; fi
          echo "start_iso=$START_ISO" >> $GITHUB_OUTPUT

      - name: Near-now RAW tail-fill (Worker fallback)
        run: |
          NOW_ISO=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          TAIL_START=$(date -u -d "$NOW_ISO - 120 minutes" +"%Y-%m-%dT%H:%M:%SZ")
          body=$(jq -nc --arg s "${{ matrix.site }}" --arg a "$TAIL_START" --arg b "$NOW_ISO" '{siteName:$s, start_time:$a, end_time:$b, chunk_minutes:5, max_chunks:12}')
          curl -sS -X POST "$PROXY_URL/api/admin/supa-backfill" \
            -H "Content-Type: application/json" \
            -H "Authorization: Bearer $ACE_API_KEY" \
            --data "$body" || true

      - name: Daily full-day backfill (previous 24 hours)
        if: ${{ github.event_name == 'schedule' }}
        run: |
          # Daily scheduled run: backfill full previous day (24 hours)
          YESTERDAY=$(date -u -d "yesterday" +"%Y-%m-%d")
          START="${YESTERDAY}T00:00:00Z"
          END="${YESTERDAY}T23:59:59Z"
          python scripts/python/backfill_paginated_raw.py \
            --site "${{ matrix.site }}" \
            --start "$START" \
            --end "$END" \
            --chunk-minutes 30 \
            --page-size 100000 \
            --max-chunks 60

      - name: Near-now RAW tail-fill (per site)
        if: ${{ github.event_name != 'schedule' }}
        run: |
          # Manual trigger: Tail-fill last 180 minutes up to now for freshness
          NOW_ISO=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          TAIL_START=$(date -u -d "$NOW_ISO - 180 minutes" +"%Y-%m-%dT%H:%M:%SZ")
          python scripts/python/backfill_paginated_raw.py \
            --site "${{ matrix.site }}" \
            --start "$TAIL_START" \
            --end "$NOW_ISO" \
            --chunk-minutes "${{ github.event.inputs.chunk_minutes || '10' }}" \
            --page-size "${{ github.event.inputs.page_size || '10000' }}" \
            --max-chunks "${{ github.event.inputs.max_chunks || '12' }}"

      - name: Deep RAW backfill to Jan 1 (per site)
        if: ${{ github.event_name == 'workflow_dispatch' }}
        run: |
          END_ARG=""
          if [ -n "${{ github.event.inputs.end_iso }}" ]; then END_ARG="--end \"${{ github.event.inputs.end_iso }}\""; fi
          python scripts/python/backfill_paginated_raw.py \
            --site "${{ matrix.site }}" \
            --start "${{ steps.when.outputs.start_iso }}" \
            $END_ARG \
            --chunk-minutes "${{ github.event.inputs.chunk_minutes || '10' }}" \
            --page-size "${{ github.event.inputs.page_size || '100000' }}" \
            --max-chunks "${{ github.event.inputs.max_chunks || '60' }}"
      - name: ACE sanity probe (last 10 minutes)
        env:
          ACE_API_KEY: ${{ secrets.ACE_API_KEY }}
          ACE_API_BASE: https://flightdeck.aceiot.cloud/api
        shell: bash
        run: |
          set -euo pipefail
          NOW=$(date -u +"%Y-%m-%dT%H:%M:%SZ")
          START=$(date -u -d "$NOW - 10 minutes" +"%Y-%m-%dT%H:%M:%SZ")
          url="$ACE_API_BASE/sites/${{ matrix.site }}/timeseries/paginated?start_time=$START&end_time=$NOW&raw_data=true&page_size=10000"
          echo "GET $url" >&2
          resp=$(curl -sS "$url" -H "authorization: Bearer $ACE_API_KEY" -H 'accept: application/json') || true
          echo "${resp:0:512}..." | sed 's/\n/ /g'
          echo "$resp" | jq -r '(.point_samples|length) as $n | "ace_sanity_point_samples=",$n' || true

      - name: Configured points sanity probe
        env:
          ACE_API_KEY: ${{ secrets.ACE_API_KEY }}
          ACE_API_BASE: https://flightdeck.aceiot.cloud/api
        shell: bash
        run: |
          set -euo pipefail
          url="$ACE_API_BASE/sites/${{ matrix.site }}/configured_points?page=1&per_page=100"
          code=$(curl -s -o /dev/null -w "%{http_code}" "$url" -H "authorization: Bearer $ACE_API_KEY" -H 'accept: application/json')
          echo "configured_points_http_code=$code"
